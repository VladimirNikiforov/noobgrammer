{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-758d29429358>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "image_size = mnist.train.images.shape[1]  # 784\n",
    "image_dim = int(image_size ** 0.5)  # 28\n",
    "num_labels = 10\n",
    "color_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders\n",
    "\n",
    "# Placeholder for the incoming 1D data \n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,image_size])\n",
    "\n",
    "# Convolutional network accepts 2D data. So resize it from 1,784 to 28x28\n",
    "x_image = tf.reshape(x,[-1,image_dim,image_dim,color_channels])\n",
    "\n",
    "# Placeholder for the labels (one hot encoded)\n",
    "y_true = tf.placeholder(dtype=tf.float32,shape=[None,num_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph creation\n",
    "\n",
    "conv --> max pool --> conv --> max pool --> flatten --> fully connected --> drop out --> fully connected (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_layer_1 = tf.layers.conv2d(inputs=x_image,\n",
    "                                 filters=32,\n",
    "                                 kernel_size=[5,5],\n",
    "                                 padding=\"same\",\n",
    "                                 activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer_1 = tf.layers.max_pooling2d(inputs=convo_layer_1,\n",
    "                                       pool_size=[2,2],\n",
    "                                       strides=[2,2],\n",
    "                                       padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_layer_2 = tf.layers.conv2d(inputs=pool_layer_1,\n",
    "                                 filters=64,\n",
    "                                 kernel_size=[5,5],\n",
    "                                 padding=\"same\",\n",
    "                                 activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer_2 = tf.layers.max_pooling2d(inputs=convo_layer_2,\n",
    "                                       pool_size=[2,2],\n",
    "                                       strides=[2,2],\n",
    "                                       padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the layer before sending it into the fully connected layer\n",
    "flat_layer = tf.layers.flatten(pool_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_layer_1 = tf.contrib.layers.fully_connected(inputs=flat_layer,num_outputs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dropout layer which randomly drops neurons with probability = 0.5\n",
    "# this is useful to avoid over fitting of data\n",
    "\n",
    "drop_prob = tf.placeholder(dtype=tf.float32)\n",
    "dropout_layer = tf.layers.dropout(inputs=fully_connected_layer_1,rate=drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the final output data \n",
    "\n",
    "output_layer = tf.contrib.layers.fully_connected(inputs=dropout_layer,num_outputs=num_labels,activation_fn=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Graph creation completed\n",
    "### moving onto creating functions (cost) and the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_true, logits = output_layer)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing all the variables\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0\n",
      "0.1315\n",
      "\n",
      "Step : 100\n",
      "0.8359\n",
      "\n",
      "Step : 200\n",
      "0.9455\n",
      "\n",
      "Step : 300\n",
      "0.9603\n",
      "\n",
      "Step : 400\n",
      "0.9689\n",
      "\n",
      "Step : 500\n",
      "0.9685\n",
      "\n",
      "Step : 600\n",
      "0.9639\n",
      "\n",
      "Step : 700\n",
      "0.9647\n",
      "\n",
      "Step : 800\n",
      "0.9753\n",
      "\n",
      "Step : 900\n",
      "0.9721\n",
      "\n",
      "Step : 1000\n",
      "0.9774\n",
      "\n",
      "Step : 1100\n",
      "0.9783\n",
      "\n",
      "Step : 1200\n",
      "0.9816\n",
      "\n",
      "Step : 1300\n",
      "0.98\n",
      "\n",
      "Step : 1400\n",
      "0.9774\n",
      "\n",
      "Step : 1500\n",
      "0.9747\n",
      "\n",
      "Step : 1600\n",
      "0.982\n",
      "\n",
      "Step : 1700\n",
      "0.9711\n",
      "\n",
      "Step : 1800\n",
      "0.9826\n",
      "\n",
      "Step : 1900\n",
      "0.9765\n",
      "\n",
      "Step : 2000\n",
      "0.9641\n",
      "\n",
      "Step : 2100\n",
      "0.9838\n",
      "\n",
      "Step : 2200\n",
      "0.9725\n",
      "\n",
      "Step : 2300\n",
      "0.9739\n",
      "\n",
      "Step : 2400\n",
      "0.9739\n",
      "\n",
      "Step : 2500\n",
      "0.9813\n",
      "\n",
      "Step : 2600\n",
      "0.9816\n",
      "\n",
      "Step : 2700\n",
      "0.9855\n",
      "\n",
      "Step : 2800\n",
      "0.9843\n",
      "\n",
      "Step : 2900\n",
      "0.9843\n",
      "\n",
      "Step : 3000\n",
      "0.9823\n",
      "\n",
      "Step : 3100\n",
      "0.9835\n",
      "\n",
      "Step : 3200\n",
      "0.9837\n",
      "\n",
      "Step : 3300\n",
      "0.9828\n",
      "\n",
      "Step : 3400\n",
      "0.9811\n",
      "\n",
      "Step : 3500\n",
      "0.9841\n",
      "\n",
      "Step : 3600\n",
      "0.9774\n",
      "\n",
      "Step : 3700\n",
      "0.9837\n",
      "\n",
      "Step : 3800\n",
      "0.9842\n",
      "\n",
      "Step : 3900\n",
      "0.9821\n",
      "\n",
      "Step : 4000\n",
      "0.9814\n",
      "\n",
      "Step : 4100\n",
      "0.9818\n",
      "\n",
      "Step : 4200\n",
      "0.9823\n",
      "\n",
      "Step : 4300\n",
      "0.9786\n",
      "\n",
      "Step : 4400\n",
      "0.985\n",
      "\n",
      "Step : 4500\n",
      "0.9693\n",
      "\n",
      "Step : 4600\n",
      "0.9831\n",
      "\n",
      "Step : 4700\n",
      "0.9856\n",
      "\n",
      "Step : 4800\n",
      "0.9831\n",
      "\n",
      "Step : 4900\n",
      "0.9813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(5000):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size=50)\n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,drop_prob:0.5})\n",
    "        if i%100 == 0 :\n",
    "            matches = tf.equal(tf.argmax(output_layer,1),tf.argmax(y_true,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(matches,dtype=tf.float32))\n",
    "            res = sess.run(accuracy,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,drop_prob:0})\n",
    "            print(\"Step : %s\" % i)\n",
    "            print(res)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final accuracy on the test set is around 98 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
